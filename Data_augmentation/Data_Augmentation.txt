DA is an approach of generating more training data from an existing training samples to avoid 
	overfitting the model. 
When applying DA for model. if we use ANN, we must use a dropout layer before the dense connected
	classifier, because there still intercorrelation between both data.
The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training 
	time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such 
	that the sum over all inputs is unchanged.

There are many ways for data augmentation:

1. Word embeddings:
	DataSet --> Find Keywords in the data --> find similar words ---> replace keywords

2. BERT( Bidirectional Encoder Representation from Transformer):
	A. Mask Word Prediction: 
		Dataset --> Mask Keywords --> Masked word (finding similar words) --> Augmented data
	B. Next Sentence Prediction:

3. Back Translation (Best Tech in DA in NLP) :
	BT uses deep neural networks to generate a new sentences which have the same meaning
	of the original sentences. (mostly for translation between languages)

4: T5 ( Text to Text Transfer Transformer)
	
5: Ensemble approach: 
	Applying different DA approaches and merge them to get a new output
